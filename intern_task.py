# -*- coding: utf-8 -*-
"""Intern_task.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aZztBYTxi5PiUXpDwRuvD5nSngimA7gM
"""

pip install pandas-profiling==2.7.1

import pandas as pd
import pandas_profiling
import numpy as np
from pandas_profiling import ProfileReport
pd.set_option('display.max_columns', None)
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

df=pd.read_csv('training_data.csv')
print(df)

#generate profile report
profile= ProfileReport(df)
profile.to_file(output_file="profile1.html")

# Read in data and display first 5 rows
features = pd.read_csv('training_data.csv')
test_file_data= pd.read_csv('test_data.csv')
print(features.head(5))

features=features.drop(['unit','patient_id','created_at'],axis=1)

features.head(5)

print('The shape of our features is:', features.shape)

# Descriptive statistics for each column
features.describe()

print(features.values)

gender_list = features['gender'].unique().tolist()

gender_list

features["gender"] = features["gender"].str.lower()

gender_list_new=features['gender'].unique().tolist()
print(gender_list_new)

from sklearn import preprocessing
  
# label_encoder object knows how to understand word labels.
label_encoder = preprocessing.LabelEncoder()
  
# Encode labels in column 'species'.
features['gender']= label_encoder.fit_transform(features['gender'])
  
features['gender'].unique()

labels = np.array(features['gender'])

# Remove the labels from the features
# axis 1 refers to the columns
features= features.drop('gender', axis = 1)

labels

features_encoded = pd.get_dummies(features)

features_encoded.head(5)

feature_encoded_list = list(features_encoded.columns)
x_array = np.array(features_encoded)

x_array.shape

labels.shape

y_array=labels.reshape((10000,1))

# Using Skicit-learn to split data into training and testing sets
from sklearn.model_selection import train_test_split
#Split the data into training and testing sets
x_train, x_test, y_train,y_test = train_test_split(x_array, y_array, test_size = 0.20, random_state = 42)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

"""Using logistic regression

"""

#using logistic regression
logreg = LogisticRegression()

logreg.fit(x_train, y_train)

y_pred_logreg = logreg.predict(x_test)

logreg.score(x_train, y_train)

"""Using support vector machines

"""

svc = SVC()

svc.fit(x_train, y_train)

y_pred_svm = svc.predict(x_test)

svc.score(x_train, y_train)

"""using random forest

"""

random_forest = RandomForestClassifier(n_estimators=100,oob_score=True,max_features=5)

random_forest.fit(x_train, y_train)

y_pred_rf = random_forest.predict(x_test)

random_forest.score(x_train, y_train)

"""using gradeint boost

"""

grad_boost = GradientBoostingClassifier(n_estimators=1000)
grad_boost.fit(x_train, y_train)
y_pred_grad = grad_boost.predict(x_test)
grad_boost.score(x_train, y_train)

"""predictions using test file

"""

test_data=test_file_data.drop(['unit','patient_id','created_at'],axis=1)
test_data = test_data.iloc[: , 1:]
test_data_encoded = pd.get_dummies(test_data)
x_test_file = np.array(test_data_encoded)

test_data_encoded.head(5)

predictions = random_forest.predict(x_test_file)

print(predictions)

print(label_encoder.inverse_transform(predictions)[:10])

"""Accuracy measures"""

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_pred_rf)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(classification_report(y_pred_rf,y_test))
print(accuracy_score(y_pred_rf, y_test))

from sklearn import datasets, metrics, model_selection, svm
metrics.plot_roc_curve(random_forest, x_test, y_test)

